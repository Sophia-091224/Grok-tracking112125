# é£Ÿå“æº¯æºAIç³»çµ± - å®Œæ•´æŠ€è¡“è¦æ ¼æ›¸
## Food Traceability AI System - Comprehensive Technical Specifications

**ç‰ˆæœ¬**: 2.0.0  
**æ—¥æœŸ**: 2025-01-21  
**ä½œè€…**: Food Safety Intelligence Team  
**èªè¨€**: Traditional Chinese (ç¹é«”ä¸­æ–‡) / English

---

## ğŸ“‹ ç›®éŒ„ (Table of Contents)

1. [ç³»çµ±æ¦‚è¿°](#ç³»çµ±æ¦‚è¿°)
2. [æ¶æ§‹è¨­è¨ˆ](#æ¶æ§‹è¨­è¨ˆ)
3. [SDS (Software Design Specification) æ¶æ§‹](#sds-æ¶æ§‹)
4. [é€²éšPromptç’°å¢ƒè¨­å®š](#é€²éšpromptç’°å¢ƒè¨­å®š)
5. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
6. [APIè¦æ ¼](#apiè¦æ ¼)
7. [æ•¸æ“šæ¨¡å‹](#æ•¸æ“šæ¨¡å‹)
8. [å®‰å…¨æ€§èˆ‡éš±ç§](#å®‰å…¨æ€§èˆ‡éš±ç§)
9. [æ€§èƒ½å„ªåŒ–](#æ€§èƒ½å„ªåŒ–)
10. [ç›£æ§èˆ‡ç¶­è­·](#ç›£æ§èˆ‡ç¶­è­·)

---

## 1. ç³»çµ±æ¦‚è¿°

### 1.1 å°ˆæ¡ˆç°¡ä»‹

**é£Ÿå“æº¯æºAIç³»çµ±**æ˜¯ä¸€å€‹çµåˆå¤šLLMï¼ˆLarge Language Modelï¼‰æŠ€è¡“çš„æ™ºèƒ½åˆ†æå¹³å°ï¼Œå°ˆç‚ºé£Ÿå“ä¾›æ‡‰éˆè¿½æº¯ã€é¢¨éšªè©•ä¼°å’Œæ•¸æ“šå¯è¦–åŒ–è€Œè¨­è¨ˆã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ğŸ“Š è‡ªå‹•åŒ–æ•¸æ“šæ¸…ç†èˆ‡é©—è­‰
- ğŸ” æ·±åº¦æ•¸æ“šæŒ–æ˜èˆ‡çµ±è¨ˆåˆ†æ
- ğŸ“ˆ äº’å‹•å¼è¦–è¦ºåŒ–å„€è¡¨æ¿
- âš ï¸ å³æ™‚é¢¨éšªè©•ä¼°èˆ‡å‘Šè­¦
- ğŸ¤– 31å€‹å°ˆæ¥­AIä»£ç†å”åŒå·¥ä½œ
- ğŸŒ å¤šèªè¨€æ”¯æŒï¼ˆç¹ä¸­ã€ç°¡ä¸­ã€è‹±æ–‡ã€æ—¥æ–‡ï¼‰

### 1.2 æŠ€è¡“æ£§

| å±¤ç´š | æŠ€è¡“ | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|------|
| **å‰ç«¯** | React | 18.2+ | UIæ¡†æ¶ |
| | TailwindCSS | 3.4+ | æ¨£å¼è¨­è¨ˆ |
| | Lucide React | 0.263+ | åœ–æ¨™åº« |
| | Plotly.js | 2.27+ | æ•¸æ“šè¦–è¦ºåŒ– |
| | D3.js | 7.8+ | é«˜ç´šåœ–è¡¨ |
| **å¾Œç«¯** | Python | 3.10+ | ä¸»è¦èªè¨€ |
| | Streamlit | 1.29+ | å¿«é€ŸåŸå‹ |
| | FastAPI | 0.108+ | ç”Ÿç”¢API |
| | Pandas | 2.1+ | æ•¸æ“šè™•ç† |
| | NumPy | 1.26+ | æ•¸å€¼è¨ˆç®— |
| **AI/ML** | OpenAI API | gpt-4o | ä¸»åŠ›LLM |
| | Google Gemini | 1.5-pro | æ›¿ä»£LLM |
| | xAI Grok | beta | å¯¦é©—æ€§LLM |
| | Scikit-learn | 1.3+ | æ©Ÿå™¨å­¸ç¿’ |
| | TensorFlow | 2.15+ | æ·±åº¦å­¸ç¿’ |
| **æ•¸æ“šåº«** | PostgreSQL | 15+ | é—œè¯å¼æ•¸æ“šåº« |
| | MongoDB | 7.0+ | æ–‡æª”æ•¸æ“šåº« |
| | Redis | 7.2+ | å¿«å–å±¤ |
| **éƒ¨ç½²** | Docker | 24.0+ | å®¹å™¨åŒ– |
| | Kubernetes | 1.28+ | ç·¨æ’ |
| | AWS/GCP/Azure | - | é›²å¹³å° |

### 1.3 ç³»çµ±éœ€æ±‚

**æœ€ä½ç¡¬ä»¶è¦æ±‚**ï¼š
- CPU: 4æ ¸å¿ƒ @ 2.5GHz
- RAM: 16GB
- å„²å­˜: 100GB SSD
- ç¶²çµ¡: 10Mbpsä¸Šå‚³/ä¸‹è¼‰

**æ¨è–¦ç¡¬ä»¶é…ç½®**ï¼š
- CPU: 8æ ¸å¿ƒ @ 3.5GHz (Intel Xeon / AMD EPYC)
- RAM: 32GB DDR4
- å„²å­˜: 500GB NVMe SSD
- GPU: NVIDIA Tesla T4 (ç”¨æ–¼MLæ¨¡å‹æ¨ç†)
- ç¶²çµ¡: 100Mbpså°ˆç·š

---

## 2. æ¶æ§‹è¨­è¨ˆ

### 2.1 ç³»çµ±æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ¶å±¤ (User Layer)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Web UI   â”‚  â”‚ Mobile   â”‚  â”‚ Desktop  â”‚  â”‚ API      â”‚   â”‚
â”‚  â”‚ React    â”‚  â”‚ App      â”‚  â”‚ Electron â”‚  â”‚ Clients  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     API Gateway (Nginx / Kong)       â”‚
         â”‚  â€¢ èªè­‰/æˆæ¬Š  â€¢ é™æµ  â€¢ è² è¼‰å¹³è¡¡     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         æ‡‰ç”¨å±¤ (Application Layer)    â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
         â”‚  â”‚  FastAPI / Streamlit Server â”‚    â”‚
         â”‚  â”‚  â€¢ RESTful API              â”‚    â”‚
         â”‚  â”‚  â€¢ WebSocket (å³æ™‚æ›´æ–°)     â”‚    â”‚
         â”‚  â”‚  â€¢ æ–‡ä»¶ä¸Šå‚³è™•ç†             â”‚    â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      AIä»£ç†ç·¨æ’å±¤ (Agent Layer)  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
         â”‚  â”‚  Agent Orchestrator        â”‚ â”‚
         â”‚  â”‚  (agent_031 - å”èª¿å“¡)      â”‚ â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â”‚         â”‚                        â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ æ•¸æ“šæ¸…ç†çµ„  â”‚çµ±è¨ˆçµ„â”‚è¦–è¦ºçµ„â”‚  â”‚
         â”‚  â”‚ Agent 1-6   â”‚7-13  â”‚14-20 â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
         â”‚  â”‚é¢¨éšªçµ„â”‚ AIå¢å¼·çµ„             â”‚â”‚
         â”‚  â”‚21-26 â”‚ 27-31                â”‚â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      LLMæœå‹™å±¤ (LLM Layer)       â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â” â”‚
         â”‚  â”‚OpenAIâ”‚  â”‚ Gemini â”‚  â”‚Grok â”‚ â”‚
         â”‚  â”‚ API  â”‚  â”‚  API   â”‚  â”‚ API â”‚ â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      æ•¸æ“šå±¤ (Data Layer)         â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚  â”‚PostgreSQLâ”‚  â”‚ MongoDB  â”‚     â”‚
         â”‚  â”‚(çµæ§‹åŒ–)  â”‚  â”‚(éçµæ§‹åŒ–)â”‚     â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚  â”‚  Redis   â”‚  â”‚  S3/Blob â”‚     â”‚
         â”‚  â”‚ (å¿«å–)   â”‚  â”‚ (æ–‡ä»¶å­˜å„²)â”‚     â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ•¸æ“šæµç¨‹

1. **ä¸Šå‚³éšæ®µ**ï¼š
   - ç”¨æˆ¶ä¸Šå‚³JSON/CSVæ–‡ä»¶ â†’ API Gateway â†’ æ–‡ä»¶é©—è­‰ â†’ å­˜å„²è‡³S3
   - è§¸ç™¼æ•¸æ“šè™•ç†ç®¡é“

2. **è™•ç†éšæ®µ**ï¼š
   - Agent Orchestratoræ¥æ”¶ä»»å‹™
   - ä¸¦è¡Œèª¿ç”¨æ•¸æ“šæ¸…ç†çµ„ï¼ˆAgents 1-6ï¼‰
   - ä¾åºåŸ·è¡Œçµ±è¨ˆåˆ†æï¼ˆAgents 7-13ï¼‰
   - ç”Ÿæˆè¦–è¦ºåŒ–ï¼ˆAgents 14-20ï¼‰

3. **åˆ†æéšæ®µ**ï¼š
   - é¢¨éšªè©•ä¼°çµ„ï¼ˆAgents 21-26ï¼‰è©•åˆ†
   - AIå¢å¼·çµ„ï¼ˆAgents 27-31ï¼‰æä¾›æ™ºèƒ½æ´å¯Ÿ
   - ç”Ÿæˆç¶œåˆå ±å‘Š

4. **è¼¸å‡ºéšæ®µ**ï¼š
   - æ•¸æ“šå­˜å…¥PostgreSQL/MongoDB
   - å¿«å–ç†±æ•¸æ“šè‡³Redis
   - WebSocketæ¨é€å³æ™‚æ›´æ–°è‡³å‰ç«¯
   - ç”Ÿæˆå¯ä¸‹è¼‰PDFå ±å‘Š

---

## 3. SDS (Software Design Specification) æ¶æ§‹

### 3.1 æ¨¡å¡ŠåŒ–è¨­è¨ˆ

#### 3.1.1 æ ¸å¿ƒæ¨¡å¡Š

```python
# å°ˆæ¡ˆçµæ§‹
food_traceability_ai/
â”‚
â”œâ”€â”€ app.py                      # Streamlitä¸»æ‡‰ç”¨
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                 # FastAPIå…¥å£
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ upload.py           # æ–‡ä»¶ä¸Šå‚³è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ analysis.py         # åˆ†æè·¯ç”±
â”‚   â”‚   â”œâ”€â”€ agents.py           # ä»£ç†åŸ·è¡Œè·¯ç”±
â”‚   â”‚   â””â”€â”€ reports.py          # å ±å‘Šç”Ÿæˆè·¯ç”±
â”‚   â””â”€â”€ middleware/
â”‚       â”œâ”€â”€ auth.py             # èªè­‰ä¸­é–“ä»¶
â”‚       â””â”€â”€ rate_limit.py       # é™æµä¸­é–“ä»¶
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ orchestrator.py         # ä»£ç†å”èª¿å™¨ (Agent 31)
â”‚   â”œâ”€â”€ data_cleaning/
â”‚   â”‚   â”œâ”€â”€ agent_001.py        # æ•¸æ“šçµæ§‹åˆ†æå¸«
â”‚   â”‚   â”œâ”€â”€ agent_002.py        # ç¼ºå¤±å€¼è¨ºæ–·
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ statistical/
â”‚   â”‚   â”œâ”€â”€ agent_007.py        # æè¿°æ€§çµ±è¨ˆ
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ agent_014.py        # å„€è¡¨æ¿è¨­è¨ˆ
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ risk_assessment/
â”‚   â”‚   â”œâ”€â”€ agent_021.py        # é¢¨éšªè©•åˆ†
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ai_enhanced/
â”‚       â”œâ”€â”€ agent_027.py        # NLPæŸ¥è©¢
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ data_models.py          # Pydanticæ•¸æ“šæ¨¡å‹
â”‚   â”œâ”€â”€ ml_models/
â”‚   â”‚   â”œâ”€â”€ anomaly_detector.py # ç•°å¸¸æª¢æ¸¬æ¨¡å‹
â”‚   â”‚   â””â”€â”€ risk_predictor.py   # é¢¨éšªé æ¸¬æ¨¡å‹
â”‚   â””â”€â”€ schemas/
â”‚       â”œâ”€â”€ batch_schema.json   # æ‰¹æ¬¡æ•¸æ“šæ¶æ§‹
â”‚       â””â”€â”€ farm_schema.json    # è¾²å ´æ•¸æ“šæ¶æ§‹
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ llm_service.py          # LLMçµ±ä¸€æ¥å£
â”‚   â”œâ”€â”€ data_service.py         # æ•¸æ“šè™•ç†æœå‹™
â”‚   â”œâ”€â”€ visualization_service.py# è¦–è¦ºåŒ–æœå‹™
â”‚   â””â”€â”€ notification_service.py # å‘Šè­¦é€šçŸ¥æœå‹™
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_validator.py       # æ•¸æ“šé©—è­‰å·¥å…·
â”‚   â”œâ”€â”€ date_parser.py          # æ—¥æœŸè§£æå·¥å…·
â”‚   â”œâ”€â”€ logger.py               # æ—¥èªŒå·¥å…·
â”‚   â””â”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agents.yaml             # ä»£ç†é…ç½®ï¼ˆå·²å‰µå»ºï¼‰
â”‚   â”œâ”€â”€ settings.yaml           # ç³»çµ±è¨­å®š
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ system_prompts.yaml # ç³»çµ±æç¤ºè©åº«
â”‚       â””â”€â”€ user_prompts.yaml   # ç”¨æˆ¶æç¤ºè©æ¨¡æ¿
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # åŸå§‹ä¸Šå‚³æ•¸æ“š
â”‚   â”œâ”€â”€ processed/              # è™•ç†å¾Œæ•¸æ“š
â”‚   â””â”€â”€ models/                 # è¨“ç·´å¥½çš„MLæ¨¡å‹
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agents.py          # ä»£ç†å–®å…ƒæ¸¬è©¦
â”‚   â”œâ”€â”€ test_api.py             # APIæ¸¬è©¦
â”‚   â””â”€â”€ test_integration.py     # é›†æˆæ¸¬è©¦
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile              # æ‡‰ç”¨å®¹å™¨
â”‚   â”œâ”€â”€ Dockerfile.nginx        # Nginxå®¹å™¨
â”‚   â””â”€â”€ docker-compose.yml      # å¤šå®¹å™¨ç·¨æ’
â”‚
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml         # Kuberneteséƒ¨ç½²
â”‚   â”œâ”€â”€ service.yaml            # æœå‹™å®šç¾©
â”‚   â””â”€â”€ ingress.yaml            # å…¥å£é…ç½®
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md                  # APIæ–‡æª”
â”‚   â”œâ”€â”€ AGENTS.md               # ä»£ç†ä½¿ç”¨æŒ‡å—
â”‚   â””â”€â”€ DEPLOYMENT.md           # éƒ¨ç½²æ–‡æª”
â”‚
â”œâ”€â”€ requirements.txt            # Pythonä¾è³´
â”œâ”€â”€ .env.example                # ç’°å¢ƒè®Šé‡ç¤ºä¾‹
â””â”€â”€ README.md                   # å°ˆæ¡ˆèªªæ˜
```

#### 3.1.2 é—œéµé¡è¨­è¨ˆ

```python
# models/data_models.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict
from datetime import datetime
from enum import Enum

class RiskLevel(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class Batch(BaseModel):
    batch_id: str = Field(..., description="æ‰¹æ¬¡å”¯ä¸€ID")
    farm_id: str
    farm_name: str
    laying_date: datetime
    packing_date: Optional[datetime]
    distribution_date: Optional[datetime]
    quantity: int = Field(gt=0)
    temperature_records: List[float] = []
    risk_score: Optional[float] = Field(None, ge=0, le=10)
    risk_level: Optional[RiskLevel] = None
    metadata: Dict = {}

class AnalysisRequest(BaseModel):
    dataset: List[Batch]
    agents_to_run: List[str] = Field(default=["agent_031"])
    parameters: Dict = {
        "temperature": 0.2,
        "max_tokens": 2000
    }

class AnalysisResult(BaseModel):
    request_id: str
    timestamp: datetime
    summary: str
    risk_assessment: Dict
    visualizations: List[str]  # URLs to generated charts
    recommendations: List[str]
    agent_outputs: Dict  # Individual agent results
```

```python
# services/llm_service.py
from abc import ABC, abstractmethod
from typing import Dict, List
import openai
import google.generativeai as genai

class LLMProvider(ABC):
    @abstractmethod
    def generate(self, prompt: str, **kwargs) -> str:
        pass

class OpenAIProvider(LLMProvider):
    def __init__(self, api_key: str, model: str = "gpt-4o"):
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
    
    def generate(self, prompt: str, **kwargs) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=kwargs.get("temperature", 0.2),
            max_tokens=kwargs.get("max_tokens", 2000)
        )
        return response.choices[0].message.content

class GeminiProvider(LLMProvider):
    def __init__(self, api_key: str, model: str = "gemini-1.5-pro"):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model)
    
    def generate(self, prompt: str, **kwargs) -> str:
        generation_config = genai.types.GenerationConfig(
            temperature=kwargs.get("temperature", 0.2),
            max_output_tokens=kwargs.get("max_tokens", 2000)
        )
        response = self.model.generate_content(
            prompt,
            generation_config=generation_config
        )
        return response.text

class LLMService:
    def __init__(self):
        self.providers: Dict[str, LLMProvider] = {}
    
    def register_provider(self, name: str, provider: LLMProvider):
        self.providers[name] = provider
    
    def generate(self, provider_name: str, prompt: str, **kwargs) -> str:
        if provider_name not in self.providers:
            raise ValueError(f"Provider {provider_name} not registered")
        return self.providers[provider_name].generate(prompt, **kwargs)
```

### 3.2 è¨­è¨ˆæ¨¡å¼

1. **ç­–ç•¥æ¨¡å¼ (Strategy Pattern)**: ä¸åŒLLMæä¾›è€…çš„æŠ½è±¡
2. **å·¥å» æ¨¡å¼ (Factory Pattern)**: ä»£ç†å¯¦ä¾‹åŒ–
3. **è§€å¯Ÿè€…æ¨¡å¼ (Observer Pattern)**: å³æ™‚å‘Šè­¦é€šçŸ¥
4. **è²¬ä»»éˆæ¨¡å¼ (Chain of Responsibility)**: æ•¸æ“šè™•ç†ç®¡é“
5. **å–®ä¾‹æ¨¡å¼ (Singleton)**: é…ç½®ç®¡ç†å™¨

---

## 4. é€²éšPromptç’°å¢ƒè¨­å®š

### 4.1 ç³»çµ±æç¤ºè©æ¶æ§‹

```yaml
# config/prompts/system_prompts.yaml

base_system_prompt: |
  ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„é£Ÿå“å®‰å…¨èˆ‡ä¾›æ‡‰éˆåˆ†æAIåŠ©ç†ã€‚
  ä½ çš„æ ¸å¿ƒè·è²¬æ˜¯ï¼š
  1. æº–ç¢ºåˆ†æé£Ÿå“æº¯æºæ•¸æ“š
  2. è­˜åˆ¥æ½›åœ¨é¢¨éšªå’Œç•°å¸¸
  3. æä¾›å¯è¡Œå‹•çš„å»ºè­°
  4. ä½¿ç”¨æ¸…æ™°ã€å°ˆæ¥­çš„èªè¨€
  5. å§‹çµ‚ä»¥é£Ÿå“å®‰å…¨ç‚ºæœ€é«˜å„ªå…ˆ

role_specific_prompts:
  data_analyst: |
    ä½ æ˜¯è³‡æ·±æ•¸æ“šåˆ†æå¸«ï¼Œæ“…é•·ï¼š
    - çµ±è¨ˆåˆ†æå’Œå‡è¨­æª¢é©—
    - æ•¸æ“šå¯è¦–åŒ–è¨­è¨ˆ
    - æ¨¡å¼è­˜åˆ¥å’Œè¶¨å‹¢é æ¸¬
    ä½¿ç”¨ç§‘å­¸æ–¹æ³•ï¼Œæä¾›è­‰æ“šæ”¯æŒçš„çµè«–ã€‚
  
  risk_assessor: |
    ä½ æ˜¯é£Ÿå“å®‰å…¨é¢¨éšªè©•ä¼°å°ˆå®¶ï¼Œå°ˆæ³¨æ–¼ï¼š
    - HACCPé—œéµæ§åˆ¶é»åˆ†æ
    - æº«åº¦ã€æ™‚é–“ã€äº¤å‰æ±¡æŸ“é¢¨éšª
    - æ³•è¦éµå¾æ€§æª¢æŸ¥
    - å¬å›æº–å‚™åº¦è©•ä¼°
    æ¡ç”¨é é˜²æ€§æ€ç¶­ï¼Œæ¨™è¨˜æ‰€æœ‰æ½›åœ¨é¢¨éšªã€‚
  
  visualization_expert: |
    ä½ æ˜¯æ•¸æ“šå¯è¦–åŒ–è¨­è¨ˆå¸«ï¼ŒåŸå‰‡ï¼š
    - æ¸…æ™°åº¦å„ªæ–¼ç¾è§€åº¦
    - é¸æ“‡æœ€é©åˆæ•¸æ“šé¡å‹çš„åœ–è¡¨
    - ä½¿ç”¨è‰²ç›²å‹å¥½é…è‰²
    - åŒ…å«æ˜ç¢ºçš„æ¨™é¡Œå’Œæ¨™ç±¤
    - æ”¯æŒäº¤äº’å¼æ¢ç´¢

domain_knowledge: |
  é—œéµé£Ÿå“å®‰å…¨çŸ¥è­˜ï¼š
  - é›è›‹å†·è—æº«åº¦æ‡‰ä¿æŒåœ¨2-8Â°C
  - ä¿å­˜æœŸé™ï¼šæ´—é¸è›‹æœ€å¤š28å¤©
  - ç”¢è›‹åˆ°åŒ…è£æ‡‰åœ¨24å°æ™‚å…§
  - å†·éˆä¸­æ–·è¶…é2å°æ™‚è¦–ç‚ºé«˜é¢¨éšª
  - å°ç£é£Ÿå®‰æ³•è¦ï¼šéœ€å®Œæ•´è¿½æº¯è¿½è¹¤ç´€éŒ„

output_format_instructions: |
  è¼¸å‡ºæ ¼å¼è¦æ±‚ï¼š
  1. ä½¿ç”¨Markdownçµæ§‹åŒ–å…§å®¹
  2. é—œéµç™¼ç¾ä½¿ç”¨ **ç²—é«”** å¼·èª¿
  3. é¢¨éšªç­‰ç´šä½¿ç”¨æ¨™ç±¤ï¼šğŸŸ¢ä½ ğŸŸ¡ä¸­ ğŸ”´é«˜ âš«ç·Šæ€¥
  4. æ•¸æ“šè¡¨æ ¼ä½¿ç”¨æ¨™æº–Markdownè¡¨æ ¼
  5. å¼•ç”¨æ•¸æ“šæ™‚æ¨™è¨»ä¾†æºå’Œç½®ä¿¡åº¦
  6. å»ºè­°ä½¿ç”¨ç·¨è™Ÿåˆ—è¡¨
  7. æŠ€è¡“è¡“èªé¦–æ¬¡å‡ºç¾æ™‚æä¾›è§£é‡‹

constraints: |
  ç´„æŸæ¢ä»¶ï¼š
  - ä¸å¾—å½é€ æˆ–èª‡å¤§æ•¸æ“š
  - ä¸ç¢ºå®šæ™‚æ˜ç¢ºèªªæ˜
  - ä¸æä¾›é†«ç™‚æˆ–æ³•å¾‹å»ºè­°
  - å°Šé‡æ•¸æ“šéš±ç§ï¼Œä¸æ´©éœ²å€‹äººä¿¡æ¯
  - æ‰¿èªAIçš„é™åˆ¶ï¼Œå»ºè­°äººå·¥è¤‡æ ¸é—œéµæ±ºç­–
```

### 4.2 æç¤ºè©æ¨¡æ¿å¼•æ“

```python
# utils/prompt_engine.py
from string import Template
from typing import Dict, Any
import yaml

class PromptEngine:
    def __init__(self, config_path: str = "config/prompts/system_prompts.yaml"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.prompts = yaml.safe_load(f)
    
    def build_prompt(self, 
                     agent_role: str, 
                     user_query: str, 
                     context_data: Dict[str, Any],
                     few_shot_examples: list = None) -> str:
        """
        æ§‹å»ºå®Œæ•´çš„æç¤ºè©
        
        Args:
            agent_role: ä»£ç†è§’è‰²ï¼ˆå¦‚ 'data_analyst'ï¼‰
            user_query: ç”¨æˆ¶æŸ¥è©¢
            context_data: ä¸Šä¸‹æ–‡æ•¸æ“šï¼ˆæ•¸æ“šé›†æ‘˜è¦ã€çµ±è¨ˆä¿¡æ¯ç­‰ï¼‰
            few_shot_examples: Few-shotå­¸ç¿’ç¯„ä¾‹
        
        Returns:
            å®Œæ•´çš„æç¤ºè©å­—ç¬¦ä¸²
        """
        prompt_parts = [
            self.prompts['base_system_prompt'],
            self.prompts['role_specific_prompts'].get(agent_role, ''),
            self.prompts['domain_knowledge'],
        ]
        
        # æ·»åŠ ä¸Šä¸‹æ–‡æ•¸æ“š
        if context_data:
            prompt_parts.append("\n## æ•¸æ“šä¸Šä¸‹æ–‡\n")
            prompt_parts.append(self._format_context(context_data))
        
        # æ·»åŠ Few-shotç¯„ä¾‹
        if few_shot_examples:
            prompt_parts.append("\n## åƒè€ƒç¯„ä¾‹\n")
            for i, example in enumerate(few_shot_examples, 1):
                prompt_parts.append(f"### ç¯„ä¾‹ {i}\n")
                prompt_parts.append(f"è¼¸å…¥: {example['input']}\n")
                prompt_parts.append(f"è¼¸å‡º: {example['output']}\n\n")
        
        # æ·»åŠ ç”¨æˆ¶æŸ¥è©¢
        prompt_parts.append("\n## ç•¶å‰ä»»å‹™\n")
        prompt_parts.append(user_query)
        
        # æ·»åŠ è¼¸å‡ºæ ¼å¼æŒ‡ç¤º
        prompt_parts.append("\n" + self.prompts['output_format_instructions'])
        prompt_parts.append("\n" + self.prompts['constraints'])
        
        return "\n".join(prompt_parts)
    
    def _format_context(self, context: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡æ•¸æ“šç‚ºMarkdown"""
        formatted = []
        for key, value in context.items():
            formatted.append(f"**{key}**: {value}")
        return "\n".join(formatted)

# ä½¿ç”¨ç¯„ä¾‹
engine = PromptEngine()
prompt = engine.build_prompt(
    agent_role="risk_assessor",
    user_query="åˆ†ææ‰¹æ¬¡ BATCH_2025_001 çš„é¢¨éšª",
    context_data={
        "æ‰¹æ¬¡ID": "BATCH_2025_001",
        "è¾²å ´": "å¿«æ¨‚è¾²å ´",
        "ç”¢è›‹æ—¥æœŸ": "2025-01-15",
        "æº«åº¦è¨˜éŒ„": [4.2, 5.1, 7.8, 9.2, 6.5],
        "é‹è¼¸æ™‚é–“": "6å°æ™‚"
    },
    few_shot_examples=[
        {
            "input": "æ‰¹æ¬¡æº«åº¦è¨˜éŒ„ï¼š[3.5, 4.0, 4.2]",
            "output": "ğŸŸ¢ ä½é¢¨éšªï¼šæº«åº¦ç©©å®šåœ¨å®‰å…¨ç¯„åœå…§"
        }
    ]
)
```

### 4.3 å‹•æ…‹æç¤ºè©å„ªåŒ–

```python
# agents/prompt_optimizer.py
class PromptOptimizer:
    """
    è‡ªå‹•å„ªåŒ–æç¤ºè©ä»¥æé«˜æº–ç¢ºæ€§å’Œæ•ˆç‡
    """
    
    def __init__(self, llm_service: LLMService):
        self.llm = llm_service
        self.performance_history = []
    
    def optimize(self, base_prompt: str, test_cases: List[Dict]) -> str:
        """
        ä½¿ç”¨æ¸¬è©¦æ¡ˆä¾‹è‡ªå‹•å„ªåŒ–æç¤ºè©
        """
        variations = self._generate_variations(base_prompt)
        best_prompt = base_prompt
        best_score = 0
        
        for variation in variations:
            score = self._evaluate_prompt(variation, test_cases)
            if score > best_score:
                best_score = score
                best_prompt = variation
        
        return best_prompt
    
    def _generate_variations(self, prompt: str) -> List[str]:
        """ç”Ÿæˆæç¤ºè©è®Šé«”"""
        variations = [
            prompt,  # åŸå§‹
            f"{prompt}\nè«‹ä¸€æ­¥æ­¥æ€è€ƒã€‚",  # Chain-of-Thought
            f"{prompt}\nè«‹æä¾›ç°¡æ½”çš„ç­”æ¡ˆã€‚",  # ç°¡æ½”ç‰ˆ
            f"è®“æˆ‘å€‘ç³»çµ±æ€§åœ°åˆ†æé€™å€‹å•é¡Œã€‚\n{prompt}",  # çµæ§‹åŒ–
        ]
        return variations
    
    def _evaluate_prompt(self, prompt: str, test_cases: List[Dict]) -> float:
        """è©•ä¼°æç¤ºè©è¡¨ç¾"""
        correct = 0
        for case in test_cases:
            response = self.llm.generate("openai", prompt + f"\n\n{case['input']}")
            if self._check_correctness(response, case['expected_output']):
                correct += 1
        return correct / len(test_cases)
```

---

## 5. éƒ¨ç½²æŒ‡å—

### 5.1 æœ¬åœ°é–‹ç™¼ç’°å¢ƒè¨­ç½®

#### æ­¥é©Ÿ1: å…‹éš†å°ˆæ¡ˆ
```bash
git clone https://github.com/your-org/food-traceability-ai.git
cd food-traceability-ai
```

#### æ­¥é©Ÿ2: å‰µå»ºè™›æ“¬ç’°å¢ƒ
```bash
# ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate  # Windows

# ä½¿ç”¨ conda
conda create -n food-ai python=3.10
conda activate food-ai
```

#### æ­¥é©Ÿ3: å®‰è£ä¾è³´
```bash
pip install -r requirements.txt
```

#### æ­¥é©Ÿ4: é…ç½®ç’°å¢ƒè®Šé‡
```bash
cp .env.example .env
# ç·¨è¼¯ .env æ–‡ä»¶ï¼Œå¡«å…¥APIå¯†é‘°
```

```.env
# .env æ–‡ä»¶ç¯„ä¾‹
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
GEMINI_API_KEY=xxxxxxxxxxxxx
XAI_API_KEY=xxxxxxxxxxxxx

# æ•¸æ“šåº«é…ç½®
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=food_traceability
POSTGRES_USER=admin
POSTGRES_PASSWORD=secure_password

MONGODB_URI=mongodb://localhost:27017/
REDIS_URL=redis://localhost:6379

# æ‡‰ç”¨é…ç½®
APP_ENV=development
LOG_LEVEL=DEBUG
SECRET_KEY=your-secret-key-here
```

#### æ­¥é©Ÿ5: åˆå§‹åŒ–æ•¸æ“šåº«
```bash
# PostgreSQL
psql -U postgres -c "CREATE DATABASE food_traceability;"
python scripts/init_db.py

# MongoDB (è‡ªå‹•å‰µå»º)
```

#### æ­¥é©Ÿ6: å•Ÿå‹•æ‡‰ç”¨
```bash
# Streamlitç‰ˆæœ¬ï¼ˆé–‹ç™¼ï¼‰
streamlit run app.py --server.port=8501

# FastAPIç‰ˆæœ¬ï¼ˆç”Ÿç”¢ï¼‰
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

### 5.2 Dockeréƒ¨ç½²

#### Dockerfile
```dockerfile
# docker/Dockerfile
FROM python:3.10-slim

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# è¨­ç½®å·¥ä½œç›®éŒ„
WORKDIR /app

# è¤‡è£½ä¾è³´æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ä»£ç¢¼
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å•Ÿå‹•å‘½ä»¤
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### docker-compose.yml
```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: docker/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - POSTGRES_HOST=postgres
      - MONGODB_URI=mongodb://mongo:27017/
      - REDIS_URL=redis://redis:6379
    env_file:
      - .env
    depends_on:
      - postgres
      - mongo
      - redis
    volumes:
      - ./data:/app/data
      - ./config:/app/config
